{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import tensorflow.contrib.slim as slim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mb_size = 32\n",
    "batch_size = 32\n",
    "X_dim = [28,28,1]\n",
    "z_dim = 100\n",
    "h_dim = 128\n",
    "lr = 1e-3\n",
    "d_steps = 3\n",
    "n_class = 10\n",
    "nz = 100 # z dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7eff145e5ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)\n",
    "x_train = mnist.train.images[:50,:]\n",
    "x_train = x_train.reshape([50,28,28,1])\n",
    "#randomNum = random.randint(0,25)\n",
    "image = x_train[0]\n",
    "plt.imshow(image[:,:,0], cmap=plt.get_cmap('gray_r'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 8))\n",
    "    gs = gridspec.GridSpec(4, 8)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "    #print len(samples)\n",
    "    for i, sample in enumerate(samples):\n",
    "        #print i\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log(x):\n",
    "    return tf.log(x + 1e-8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\n",
    "            name='image', dtype=tf.float32,\n",
    "            shape=[batch_size, 28, 28, 1],\n",
    "        )\n",
    "z = tf.placeholder(tf.float32, shape=[None, nz])\n",
    "y = tf.placeholder(\n",
    "            name='label', dtype=tf.float32, shape=[batch_size, n_class],\n",
    "        )\n",
    "\n",
    "D_W1 = tf.Variable(xavier_init([28, 28, h_dim]))\n",
    "D_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "D_W2 = tf.Variable(xavier_init([h_dim, n_class]))\n",
    "D_b2 = tf.Variable(tf.zeros(shape=[n_class]))\n",
    "\n",
    "G_W1 = tf.Variable(xavier_init([z_dim, h_dim]))\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "G_W2 = tf.Variable(xavier_init([h_dim, 28, 28]))\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[28, 28]))\n",
    "\n",
    "# theta_G = [G_W1, G_W2, G_b1, G_b2]\n",
    "# theta_D = [D_W1, D_W2, D_b1, D_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "def sample_z(m, n):\n",
    "    sample = np.random.uniform(-1., 1., size=[m, n])\n",
    "    sample = sample.astype(np.float32, copy=False)\n",
    "    #y = x.view('float32')\n",
    "    #y[:] = x\n",
    "    return sample\n",
    "\n",
    "my_sample = sample_z(5,1)\n",
    "print my_sample.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_info = np.array([28, 28, 10, 1])\n",
    "\n",
    "conv_info = np.array([32, 64, 128])\n",
    "\n",
    "deconv_info = np.array([[100, 2, 1], [25, 3, 2], [6, 4, 2], [1, 6, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "    with tf.variable_scope(name):\n",
    "        f1 = 0.5 * (1 + leak)\n",
    "        f2 = 0.5 * (1 - leak)\n",
    "        return f1 * x + f2 * abs(x)\n",
    "\n",
    "def huber_loss(labels, predictions, delta=1.0):\n",
    "    residual = tf.abs(predictions - labels)\n",
    "    condition = tf.less(residual, delta)\n",
    "    small_res = 0.5 * tf.square(residual)\n",
    "    large_res = delta * residual - 0.5 * tf.square(delta)\n",
    "    return tf.where(condition, small_res, large_res)\n",
    "\n",
    "def conv2d(input, output_shape, is_train, k_h=5, k_w=5, stddev=0.02, name=\"conv2d\"):\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable('w', [k_h, k_w, input.get_shape()[-1], output_shape],\n",
    "                            initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        biases = tf.get_variable('biases', [output_shape], initializer=tf.constant_initializer(0.0))\n",
    "        conv = lrelu(tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape()))\n",
    "        bn = tf.contrib.layers.batch_norm(conv, center=True, scale=True,\n",
    "                                          decay=0.9, is_training=is_train,\n",
    "                                          updates_collections=None)\n",
    "    return bn\n",
    "\n",
    "def deconv2d(input, deconv_info, is_train, name=\"deconv2d\", stddev=0.02, activation_fn=None):\n",
    "    with tf.variable_scope(name):\n",
    "        output_shape = deconv_info[0]\n",
    "        k = deconv_info[1]\n",
    "        s = deconv_info[2]\n",
    "        deconv = layers.conv2d_transpose(\n",
    "            input, num_outputs=output_shape,\n",
    "            weights_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
    "            biases_initializer=tf.zeros_initializer(),\n",
    "            kernel_size=[k, k], stride=[s, s], padding='VALID'\n",
    "        )\n",
    "        if not activation_fn:\n",
    "            deconv = tf.nn.relu(deconv)\n",
    "            deconv = tf.contrib.layers.batch_norm(\n",
    "                deconv, center=True, scale=True,  decay=0.9,\n",
    "                is_training=is_train, updates_collections=None\n",
    "            )\n",
    "        else:\n",
    "            deconv = activation_fn(deconv)\n",
    "        return deconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_train=True\n",
    "image_shape = [32, 28, 28, 1]\n",
    "def G(z, scope='Generator'):\n",
    "    with tf.variable_scope(scope) as scope:\n",
    "        #log.warn(scope.name)\n",
    "        z = tf.reshape(z, [batch_size, 1, 1, -1])\n",
    "        g_1 = deconv2d(z, deconv_info[0], is_train, name='g_1_deconv')\n",
    "        #log.info('{} {}'.format(scope.name, g_1))\n",
    "        g_2 = deconv2d(g_1, deconv_info[1], is_train, name='g_2_deconv')\n",
    "        #log.info('{} {}'.format(scope.name, g_2))\n",
    "        g_3 = deconv2d(g_2, deconv_info[2], is_train, name='g_3_deconv')\n",
    "        #log.info('{} {}'.format(scope.name, g_3))\n",
    "        g_4 = deconv2d(g_3, deconv_info[3], is_train, name='g_4_deconv', activation_fn=tf.tanh)\n",
    "        #log.info('{} {}'.format(scope.name, g_4))\n",
    "        output = g_4\n",
    "        #print X.get_shape().as_list()\n",
    "        assert output.get_shape().as_list() == image_shape, output.get_shape().as_list()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def D(img, scope='Discriminator', reuse=True):\n",
    "    with tf.variable_scope(scope, reuse=reuse) as scope:\n",
    "        #if not reuse: log.warn(scope.name)\n",
    "        d_1 = conv2d(img, conv_info[0], is_train, name='d_1_conv')\n",
    "        d_1 = slim.dropout(d_1, keep_prob=0.5, is_training=is_train, scope='d_1_conv/')\n",
    "        #if not reuse: log.info('{} {}'.format(scope.name, d_1))\n",
    "        d_2 = conv2d(d_1, conv_info[1], is_train, name='d_2_conv')\n",
    "        d_2 = slim.dropout(d_2, keep_prob=0.5, is_training=is_train, scope='d_2_conv/')\n",
    "        #if not reuse: log.info('{} {}'.format(scope.name, d_2))\n",
    "        d_3 = conv2d(d_2, conv_info[2], is_train, name='d_3_conv')\n",
    "        d_3 = slim.dropout(d_3, keep_prob=0.5, is_training=is_train, scope='d_3_conv/')\n",
    "        #if not reuse: log.info('{} {}'.format(scope.name, d_3))\n",
    "        d_4 = slim.fully_connected(\n",
    "            tf.reshape(d_3, [batch_size, -1]), n_class, scope='d_4_fc', activation_fn=None)\n",
    "        #if not reuse: log.info('{} {}'.format(scope.name, d_4))\n",
    "        output = d_4\n",
    "        assert output.get_shape().as_list() == [batch_size, n_class]\n",
    "        return tf.nn.softmax(output), output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 1.0e-6\n",
    "LAMBA = 1\n",
    "# y has dim batch_size x num_classes\n",
    "# entropy 1\n",
    "def marginal_entropy(y):\n",
    "    y_1 = tf.reduce_mean(y, axis=0) #1/N sum y_i\n",
    "    y_2 = -y_1 * tf.log(y_1+epsilon)\n",
    "    y_3 = tf.reduce_sum(y_2)\n",
    "    return y_3\n",
    "\n",
    "def entropy(y):\n",
    "    #batch_size= K.int_shape(y)[0]\n",
    "    y_1 = -y * tf.log(y+epsilon)\n",
    "    y_2 = tf.reduce_sum(y_1,axis=1)\n",
    "    y_3 = tf.reduce_mean(y_2,axis=0)\n",
    "    return y_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100   2   1]\n"
     ]
    }
   ],
   "source": [
    "print deconv_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from util import log\n",
    "z = tf.random_uniform([batch_size, nz], minval=-1, maxval=1, dtype=tf.float32)\n",
    "G_sample = G(z)\n",
    "\n",
    "D_real, D_real_logits = D(X, scope='Discriminator', reuse=False)\n",
    "D_fake, D_fake_logits = D(G_sample, scope='Discriminator', reuse=True)\n",
    "\n",
    "D_target = 1./mb_size\n",
    "G_target = 1./(mb_size*2)\n",
    "\n",
    "#Z = tf.reduce_sum(tf.exp(-D_real)) + tf.reduce_sum(tf.exp(-D_fake))\n",
    "\n",
    "#D_loss = tf.reduce_sum(D_target * D_real) + log(Z)\n",
    "#G_loss = tf.reduce_sum(G_target * D_real) + tf.reduce_sum(G_target * D_fake) + log(Z)\n",
    "\n",
    "D_loss = -marginal_entropy(D_real) + entropy(D_real) - entropy(D_fake) + tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=D_real_logits)\n",
    "G_loss = -marginal_entropy(D_fake) + entropy(D_fake)\n",
    "\n",
    "all_vars = tf.trainable_variables()\n",
    "\n",
    "theta_D = [v for v in all_vars if v.name.startswith('Discriminator')]\n",
    "#log.warn(\"********* d_var ********** \"); slim.model_analyzer.analyze_vars(d_var, print_info=True)\n",
    "\n",
    "theta_G = [v for v in all_vars if v.name.startswith(('Generator'))]\n",
    "#log.warn(\"********* g_var ********** \"); slim.model_analyzer.analyze_vars(g_var, print_info=True)\n",
    "\n",
    "D_solver = (tf.train.AdamOptimizer(learning_rate=lr)\n",
    "            .minimize(D_loss, var_list=theta_D))\n",
    "G_solver = (tf.train.AdamOptimizer(learning_rate=lr)\n",
    "            .minimize(G_loss, var_list=theta_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "dir_name ='out_3/'\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0; D_loss: [ 3.; G_loss: -0.9044\n",
      "32\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "Iter: 10; D_loss: [-2.; G_loss: -0.9815\n",
      "32\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "Iter: 20; D_loss: [-2.; G_loss: -1.061\n",
      "32\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "Iter: 30; D_loss: [-2.; G_loss: -1.269\n",
      "32\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "Iter: 40; D_loss: [ 1.; G_loss: -1.361\n",
      "32\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "Iter: 50; D_loss: [ -2; G_loss: -1.373\n",
      "32\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "Iter: 60; D_loss: [-2.; G_loss: -1.326\n",
      "32\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "Iter: 70; D_loss: [-2.; G_loss: -1.484\n",
      "32\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "Iter: 80; D_loss: [-2.; G_loss: -1.389\n",
      "32\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "Iter: 90; D_loss: [ 2.; G_loss: -1.287\n",
      "32\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "#100,000 is good\n",
    "#print every 1000\n",
    "for it in range(100):\n",
    "    X_mb, y_mb = mnist.train.next_batch(mb_size)\n",
    "    X_mb = X_mb.reshape([mb_size, 28, 28, 1])\n",
    "    #z_mb = sample_z(mb_size, z_dim)\n",
    "\n",
    "    _, D_loss_curr = sess.run(\n",
    "        [D_solver, D_loss], feed_dict={X: X_mb, y: y_mb}\n",
    "    )\n",
    "\n",
    "    _, G_loss_curr = sess.run(\n",
    "        [G_solver, G_loss], feed_dict={X: X_mb, y: y_mb}\n",
    "    )\n",
    "\n",
    "    if it % 10 == 0:\n",
    "        print('Iter: {}; D_loss: {:.4}; G_loss: {:.4}'\n",
    "              .format(it, D_loss_curr, G_loss_curr))\n",
    "        \n",
    "        #z_mb = sample_z(16, z_dim)\n",
    "        samples = sess.run(G_sample)\n",
    "\n",
    "        fig = plot(samples)\n",
    "        plt.savefig(dir_name+'{}.png'\n",
    "                    .format(str(i).zfill(3)), bbox_inches='tight')\n",
    "        i += 1\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
