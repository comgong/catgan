{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import tensorflow.contrib.slim as slim\n",
    "import os\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_size = 32\n",
    "batch_size = 32\n",
    "X_dim = [28,28,1]\n",
    "z_dim = 100\n",
    "h_dim = 128\n",
    "lr = 1e-3\n",
    "d_steps = 3\n",
    "n_class = 10\n",
    "nz = 100 # z dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAADgRJREFUeJzt3X+M1PWdx/HX+6SIygZBVooW3V5jGo1y9JyQQ07jeULsSYQmgsWk4WJTalLiocScISY1MZcYY8uReFa351qIZQvaevKHuVb8Ea+JaRyUVHqgkHVtOTbLEqu1/ggi7/tjvzQr7vczw8x35jvs+/lIyM58398fbyb72u/MfL4zH3N3AYjnr8puAEA5CD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAmtfNgM2fO9J6ennYeEghlcHBQhw8ftnrWbSr8ZnadpI2STpP0n+5+X2r9np4eVavVZg4JIKFSqdS9bsNP+83sNEn/Ienrki6RtNLMLml0fwDaq5nX/PMl7Xf3AXc/IulnkpYW0xaAVmsm/OdL+sOY+weyZZ9hZqvNrGpm1ZGRkSYOB6BIzYR/vDcVPvf5YHfvdfeKu1e6u7ubOByAIjUT/gOS5oy5/yVJB5trB0C7NBP+VyRdZGZfNrPJkr4paXsxbQFotYaH+tz9qJmtkfRLjQ719bn77wrrDEBLNTXO7+7PSHqmoF4AtBGX9wJBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUU7P0mtmgpPclfSrpqLtXimgKQOs1Ff7MP7j74QL2A6CNeNoPBNVs+F3Sr8xsp5mtLqIhAO3R7NP+he5+0MzOlfSsme1195fGrpD9UVgtSRdccEGThwNQlKbO/O5+MPt5SNJTkuaPs06vu1fcvdLd3d3M4QAUqOHwm9lZZtZ1/LakxZJ2F9UYgNZq5mn/LElPmdnx/Wxx9/8upCsALddw+N19QNLfFNgLgDZiqA8IivADQRF+ICjCDwRF+IGgCD8QVBGf6kPJHnvssdxadh1GrnPOOSdZ37NnT7K+YMGCZP3KK69M1lEezvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/ENSEGeffsmVLsv7aa68l6319fUW201bvvvtuw9tOmpT+FThy5EiyPmXKlGT9zDPPzK3NnTs3ue22bduSdb4Zqjmc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqFNqnP+OO+7IrW3cuDG57bFjx4puZ0KoNY5fy8cff9xw/cUXX0xue9NNNyXr/f39yfqsWbOS9eg48wNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUDXH+c2sT9ISSYfc/dJs2QxJWyX1SBqUtMLd/9i6Nkc98cQTubVa4/i1Pjt+xhlnNNRTERYuXJisL1u2rE2dnLwdO3Yk65s3b86tDQ4OJrd94YUXkvWVK1cm61u3bs2t8V0A9Z35fyLpuhOW3SXpOXe/SNJz2X0Ap5Ca4Xf3lyS9c8LipZI2Zbc3SercUxOAcTX6mn+Wuw9JUvbz3OJaAtAOLX/Dz8xWm1nVzKojIyOtPhyAOjUa/mEzmy1J2c9DeSu6e6+7V9y9wpssQOdoNPzbJa3Kbq+S9HQx7QBol5rhN7N+SS9L+qqZHTCzb0u6T9IiM9snaVF2H8ApxNy9bQerVCperVYb3v7NN9/Mre3evTu57aJFi5L1rq6uhnpC2sDAQG7t+uuvT267d+/epo79wAMP5NbWrVvX1L47VaVSUbVatXrW5Qo/ICjCDwRF+IGgCD8QFOEHgiL8QFCn1FAfJpYnn3wyWV++fHlT+585c2ZubaJeas5QH4CaCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiComlN0A8146KGHcmut/m6Hjz76KLe2c+fO5LaXX3550e10HM78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUzXF+M+uTtETSIXe/NFt2j6TvSDr+5efr3f2ZVjWJtKGhodza448/ntx2w4YNRbfzGaneWu2DDz7IrV1zzTXJbd97772i2+k49Zz5fyLpunGWb3D3edk/gg+cYmqG391fkvROG3oB0EbNvOZfY2a/NbM+M5teWEcA2qLR8P9I0lckzZM0JOkHeSua2Wozq5pZdaLOjwacihoKv7sPu/un7n5M0o8lzU+s2+vuFXevdHd3N9ongII1FH4zmz3m7jck7S6mHQDtUs9QX7+kqyXNNLMDkr4v6WozmyfJJQ1K+m4LewTQAjXD7+4rx1n8aAt6CWvHjh3Jeq3Pnj/yyCO5tbfeequhnia6W265pewWSscVfkBQhB8IivADQRF+ICjCDwRF+IGg+OruAuzbty9Zv/XWW5P1559/vsh2TsqFF16YrE+f3tzHNu69997c2pQpU5LbrlmzJll/4403GupJks4777yGt50oOPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM89cp9RXXDz74YHLbgYGBZH3q1KnJ+rRp05L122+/PbdWazz7iiuuSNZrXQfQSrX+37V0dXXl1pYsWdLUvicCzvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/HV6+eWXc2u1xvFvuOGGZH3dunXJ+lVXXZWsn6p27dqVrL/99ttN7f/000/PrV188cVN7Xsi4MwPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0HVHOc3szmSNkv6oqRjknrdfaOZzZC0VVKPpEFJK9z9j61rtVwPP/xwbm3u3LnJbe++++6i25kQ9u/fn6wPDw83tf9rr722qe0nunrO/EclrXP3iyX9naTvmdklku6S9Jy7XyTpuew+gFNEzfC7+5C7v5rdfl/SHknnS1oqaVO22iZJy1rVJIDindRrfjPrkfQ1Sb+RNMvdh6TRPxCSzi26OQCtU3f4zWyqpJ9LWuvufzqJ7VabWdXMqiMjI430CKAF6gq/mX1Bo8H/qbv/Ils8bGazs/psSYfG29bde9294u6V7u7uInoGUICa4Tczk/SopD3u/sMxpe2SVmW3V0l6uvj2ALRKPR/pXSjpW5JeN7Pjn8FcL+k+SdvM7NuSfi9peWta7AwzZszIrTGU15jUx6TrcfbZZyfrt912W1P7n+hqht/dfy3Jcsr/WGw7ANqFK/yAoAg/EBThB4Ii/EBQhB8IivADQfHV3Wipyy67LLe2d+/epva9ePHiZH3BggVN7X+i48wPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzo+WGhwczK0dPXo0ue20adOS9bVr1zbSEjKc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMb50ZT+/v5k/cMPP8ytdXV1Jbft7e1N1vm8fnM48wNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUDXH+c1sjqTNkr4o6ZikXnffaGb3SPqOpJFs1fXu/kyrGkU5Pvnkk2T9/vvvT9YnT56cW7vxxhuT265YsSJZR3PqucjnqKR17v6qmXVJ2mlmz2a1De7+QOvaA9AqNcPv7kOShrLb75vZHknnt7oxAK11Uq/5zaxH0tck/SZbtMbMfmtmfWY2PWeb1WZWNbPqyMjIeKsAKEHd4TezqZJ+Lmmtu/9J0o8kfUXSPI0+M/jBeNu5e6+7V9y90t3dXUDLAIpQV/jN7AsaDf5P3f0XkuTuw+7+qbsfk/RjSfNb1yaAotUMv5mZpEcl7XH3H45ZPnvMat+QtLv49gC0Sj3v9i+U9C1Jr5vZrmzZekkrzWyeJJc0KOm7LekQpRr925/v5ptvTtbnzZuXW1u0aFFDPaEY9bzb/2tJ4/0GMKYPnMK4wg8IivADQRF+ICjCDwRF+IGgCD8QFF/djaRJk9K/InfeeWebOkHROPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFDm7u07mNmIpLfHLJop6XDbGjg5ndpbp/Yl0VujiuztQnev6/vy2hr+zx3crOruldIaSOjU3jq1L4neGlVWbzztB4Ii/EBQZYe/t+Tjp3Rqb53al0RvjSqlt1Jf8wMoT9lnfgAlKSX8Znadmb1hZvvN7K4yeshjZoNm9rqZ7TKzasm99JnZITPbPWbZDDN71sz2ZT/HnSatpN7uMbP/yx67XWb2TyX1NsfMXjCzPWb2OzP7l2x5qY9doq9SHre2P+03s9MkvSlpkaQDkl6RtNLd/7etjeQws0FJFXcvfUzYzK6S9GdJm9390mzZ/ZLecff7sj+c0939Xzukt3sk/bnsmZuzCWVmj51ZWtIySf+sEh+7RF8rVMLjVsaZf76k/e4+4O5HJP1M0tIS+uh47v6SpHdOWLxU0qbs9iaN/vK0XU5vHcHdh9z91ez2+5KOzyxd6mOX6KsUZYT/fEl/GHP/gDprym+X9Csz22lmq8tuZhyzsmnTj0+ffm7J/Zyo5szN7XTCzNId89g1MuN10coI/3iz/3TSkMNCd/9bSV+X9L3s6S3qU9fMze0yzszSHaHRGa+LVkb4D0iaM+b+lyQdLKGPcbn7weznIUlPqfNmHx4+Pklq9vNQyf38RSfN3DzezNLqgMeuk2a8LiP8r0i6yMy+bGaTJX1T0vYS+vgcMzsreyNGZnaWpMXqvNmHt0tald1eJenpEnv5jE6ZuTlvZmmV/Nh12ozXpVzkkw1l/Luk0yT1ufu/tb2JcZjZX2v0bC+NfrPxljJ7M7N+SVdr9FNfw5K+L+m/JG2TdIGk30ta7u5tf+Mtp7erNfrU9S8zNx9/jd3m3v5e0v9Iel3SsWzxeo2+vi7tsUv0tVIlPG5c4QcExRV+QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeC+n8jXPAdXUDJqwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9da37caa10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)\n",
    "x_train = mnist.train.images[:50,:]\n",
    "x_train = x_train.reshape([50,28,28,1])\n",
    "#randomNum = random.randint(0,25)\n",
    "image = x_train[0]\n",
    "plt.imshow(image[:,:,0], cmap=plt.get_cmap('gray_r'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 8))\n",
    "    gs = gridspec.GridSpec(4, 8)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "    #print len(samples)\n",
    "    for i, sample in enumerate(samples):\n",
    "        #print i\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(x):\n",
    "    return tf.log(x + 1e-8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\n",
    "            name='image', dtype=tf.float32,\n",
    "            shape=[batch_size, 28, 28, 1],\n",
    "        )\n",
    "z = tf.placeholder(tf.float32, shape=[None, nz])\n",
    "y = tf.placeholder(\n",
    "            name='label', dtype=tf.float32, shape=[batch_size, n_class],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "def sample_z(m, n):\n",
    "    sample = np.random.uniform(-1., 1., size=[m, n])\n",
    "    sample = sample.astype(np.float32, copy=False)\n",
    "    #y = x.view('float32')\n",
    "    #y[:] = x\n",
    "    return sample\n",
    "\n",
    "my_sample = sample_z(5,1)\n",
    "print my_sample.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = np.array([28, 28, 10, 1])\n",
    "\n",
    "conv_info = np.array([32, 64, 128])\n",
    "\n",
    "deconv_info = np.array([[100, 2, 1], [25, 3, 2], [6, 4, 2], [1, 6, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "    with tf.variable_scope(name):\n",
    "        f1 = 0.5 * (1 + leak)\n",
    "        f2 = 0.5 * (1 - leak)\n",
    "        return f1 * x + f2 * abs(x)\n",
    "\n",
    "def huber_loss(labels, predictions, delta=1.0):\n",
    "    residual = tf.abs(predictions - labels)\n",
    "    condition = tf.less(residual, delta)\n",
    "    small_res = 0.5 * tf.square(residual)\n",
    "    large_res = delta * residual - 0.5 * tf.square(delta)\n",
    "    return tf.where(condition, small_res, large_res)\n",
    "\n",
    "def conv2d(input, output_shape, is_train, k_h=5, k_w=5, stddev=0.02, name=\"conv2d\"):\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable('w', [k_h, k_w, input.get_shape()[-1], output_shape],\n",
    "                            initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        biases = tf.get_variable('biases', [output_shape], initializer=tf.constant_initializer(0.0))\n",
    "        conv = lrelu(tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape()))\n",
    "        bn = tf.contrib.layers.batch_norm(conv, center=True, scale=True,\n",
    "                                          decay=0.9, is_training=is_train,\n",
    "                                          updates_collections=None)\n",
    "    return bn\n",
    "\n",
    "def deconv2d(input, deconv_info, is_train, name=\"deconv2d\", stddev=0.02, activation_fn=None):\n",
    "    with tf.variable_scope(name):\n",
    "        output_shape = deconv_info[0]\n",
    "        k = deconv_info[1]\n",
    "        s = deconv_info[2]\n",
    "        deconv = layers.conv2d_transpose(\n",
    "            input, num_outputs=output_shape,\n",
    "            weights_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
    "            biases_initializer=tf.zeros_initializer(),\n",
    "            kernel_size=[k, k], stride=[s, s], padding='VALID'\n",
    "        )\n",
    "        if not activation_fn:\n",
    "            deconv = tf.nn.relu(deconv)\n",
    "            deconv = tf.contrib.layers.batch_norm(\n",
    "                deconv, center=True, scale=True,  decay=0.9,\n",
    "                is_training=is_train, updates_collections=None\n",
    "            )\n",
    "        else:\n",
    "            deconv = activation_fn(deconv)\n",
    "        return deconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train=True\n",
    "image_shape = [32, 28, 28, 1]\n",
    "def G(z, scope='Generator'):\n",
    "    with tf.variable_scope(scope) as scope:\n",
    "        #log.warn(scope.name)\n",
    "        z = tf.reshape(z, [batch_size, 1, 1, -1])\n",
    "        g_1 = deconv2d(z, deconv_info[0], is_train, name='g_1_deconv')\n",
    "        #log.info('{} {}'.format(scope.name, g_1))\n",
    "        g_2 = deconv2d(g_1, deconv_info[1], is_train, name='g_2_deconv')\n",
    "        #log.info('{} {}'.format(scope.name, g_2))\n",
    "        g_3 = deconv2d(g_2, deconv_info[2], is_train, name='g_3_deconv')\n",
    "        #log.info('{} {}'.format(scope.name, g_3))\n",
    "        g_4 = deconv2d(g_3, deconv_info[3], is_train, name='g_4_deconv', activation_fn=tf.tanh)\n",
    "        #log.info('{} {}'.format(scope.name, g_4))\n",
    "        output = g_4\n",
    "        #print X.get_shape().as_list()\n",
    "        assert output.get_shape().as_list() == image_shape, output.get_shape().as_list()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D(img, scope='Discriminator', reuse=True):\n",
    "    with tf.variable_scope(scope, reuse=reuse) as scope:\n",
    "        #if not reuse: log.warn(scope.name)\n",
    "        d_1 = conv2d(img, conv_info[0], is_train, name='d_1_conv')\n",
    "        d_1 = slim.dropout(d_1, keep_prob=0.5, is_training=is_train, scope='d_1_conv/')\n",
    "        #if not reuse: log.info('{} {}'.format(scope.name, d_1))\n",
    "        d_2 = conv2d(d_1, conv_info[1], is_train, name='d_2_conv')\n",
    "        d_2 = slim.dropout(d_2, keep_prob=0.5, is_training=is_train, scope='d_2_conv/')\n",
    "        #if not reuse: log.info('{} {}'.format(scope.name, d_2))\n",
    "        d_3 = conv2d(d_2, conv_info[2], is_train, name='d_3_conv')\n",
    "        d_3 = slim.dropout(d_3, keep_prob=0.5, is_training=is_train, scope='d_3_conv/')\n",
    "        #if not reuse: log.info('{} {}'.format(scope.name, d_3))\n",
    "        d_4 = slim.fully_connected(\n",
    "            tf.reshape(d_3, [batch_size, -1]), n_class, scope='d_4_fc', activation_fn=None)\n",
    "        #if not reuse: log.info('{} {}'.format(scope.name, d_4))\n",
    "        output = d_4\n",
    "        assert output.get_shape().as_list() == [batch_size, n_class]\n",
    "        return tf.nn.softmax(output), output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1.0e-6\n",
    "LAMBA = 1\n",
    "# y has dim batch_size x num_classes\n",
    "# entropy 1\n",
    "def marginal_entropy(y):\n",
    "    y_1 = tf.reduce_mean(y, axis=0) #1/N sum y_i\n",
    "    y_2 = -y_1 * tf.log(y_1+epsilon)\n",
    "    y_3 = tf.reduce_sum(y_2)\n",
    "    return y_3\n",
    "\n",
    "def entropy(y):\n",
    "    #batch_size= K.int_shape(y)[0]\n",
    "    y_1 = -y * tf.log(y+epsilon)\n",
    "    y_2 = tf.reduce_sum(y_1,axis=1)\n",
    "    y_3 = tf.reduce_mean(y_2,axis=0)\n",
    "    return y_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100   2   1]\n"
     ]
    }
   ],
   "source": [
    "print deconv_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of np arrays\n",
    "def average_grads(grads):\n",
    "    #print type(grads)\n",
    "    #print len(grads)\n",
    "    #print type(grads[0])\n",
    "    #print len(grads[0])\n",
    "    #print type(grads[0][0])\n",
    "    grads_list = []\n",
    "    for grad in grads:\n",
    "        grads_list.append(tf.reduce_mean(grad[0]))\n",
    "    print \"from average grads\"\n",
    "    print type(grads_list[0])\n",
    "    return grads_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from util import log\n",
    "z = tf.random_uniform([batch_size, nz], minval=-1, maxval=1, dtype=tf.float32)\n",
    "G_sample = G(z)\n",
    "\n",
    "D_real, D_real_logits = D(X, scope='Discriminator', reuse=False)\n",
    "D_fake, D_fake_logits = D(G_sample, scope='Discriminator', reuse=True)\n",
    "\n",
    "D_target = 1./mb_size\n",
    "G_target = 1./(mb_size*2)\n",
    "\n",
    "#Z = tf.reduce_sum(tf.exp(-D_real)) + tf.reduce_sum(tf.exp(-D_fake))\n",
    "\n",
    "#D_loss = tf.reduce_sum(D_target * D_real) + log(Z)\n",
    "#G_loss = tf.reduce_sum(G_target * D_real) + tf.reduce_sum(G_target * D_fake) + log(Z)\n",
    "\n",
    "D_loss = -marginal_entropy(D_real) + entropy(D_real) - entropy(D_fake) + tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=D_real_logits))\n",
    "G_loss = -marginal_entropy(D_fake) + entropy(D_fake)\n",
    "\n",
    "all_vars = tf.trainable_variables()\n",
    "\n",
    "theta_D = [v for v in all_vars if v.name.startswith('Discriminator')]\n",
    "#log.warn(\"********* d_var ********** \"); slim.model_analyzer.analyze_vars(d_var, print_info=True)\n",
    "\n",
    "theta_G = [v for v in all_vars if v.name.startswith(('Generator'))]\n",
    "#log.warn(\"********* g_var ********** \"); slim.model_analyzer.analyze_vars(g_var, print_info=True)\n",
    "\n",
    "D_grad_overall = (tf.train.AdamOptimizer(learning_rate=lr)\n",
    "            .compute_gradients(D_loss, var_list=theta_D, aggregation_method=tf.AggregationMethod.EXPERIMENTAL_ACCUMULATE_N))\n",
    "#D_grad = average_grads(D_grad_overall)\n",
    "D_solver = (tf.train.AdamOptimizer(learning_rate=lr)\n",
    "            .minimize(D_loss, var_list=theta_D))\n",
    "G_grad_overall = (tf.train.AdamOptimizer(learning_rate=lr)\n",
    "             .compute_gradients(G_loss, var_list=theta_G, aggregation_method=tf.AggregationMethod.EXPERIMENTAL_ACCUMULATE_N))\n",
    "#G_grad = average_grads(G_grad_overall)\n",
    "G_solver = (tf.train.AdamOptimizer(learning_rate=lr)\n",
    "            .minimize(G_loss, var_list=theta_G))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess = tf.Session()\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "\n",
    "dir_name ='out_8/'\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0; D_loss: 1.622; G_loss: -0.9404\n",
      "<type 'list'>\n",
      "1\n",
      "<type 'list'>\n",
      "14\n",
      "<type 'tuple'>\n",
      "2\n",
      "from average grads\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<type 'list'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "[0.011284144, -0.99243653, -0.011918042, 0.00048761256, -0.0020214808, -0.015450088, 0.0016709766, 9.1537484e-05, 7.8566431e-05, 0.00053625437, 0.0047074407, 0.0095790299, -3.3527612e-09, -3.7252903e-09]\n",
      "Iter: 100; D_loss: -1.838; G_loss: -1.412\n",
      "<type 'list'>\n",
      "1\n",
      "<type 'list'>\n",
      "14\n",
      "<type 'tuple'>\n",
      "2\n",
      "from average grads\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<type 'list'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "[-0.046992227, -0.036046311, -0.013212808, -0.00011777459, -9.7652061e-05, -0.0028908134, -0.0016011626, 3.5920413e-05, -6.952566e-05, 0.00041005373, -0.0013837602, 0.0042906031, 2.0489097e-09, -1.6763806e-09]\n",
      "Iter: 200; D_loss: -2.02; G_loss: -1.289\n",
      "<type 'list'>\n",
      "1\n",
      "<type 'list'>\n",
      "14\n",
      "<type 'tuple'>\n",
      "2\n",
      "from average grads\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<type 'list'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "[0.082478553, 0.019740216, -0.0045528794, 0.000160255, 6.5960026e-05, 0.0010116097, -0.0020451581, 4.508032e-05, -0.00014815289, 0.00050342223, 0.0035942518, 0.0058426792, -5.1222743e-10, 6.6123902e-09]\n",
      "Iter: 300; D_loss: -2.294; G_loss: -1.184\n",
      "<type 'list'>\n",
      "1\n",
      "<type 'list'>\n",
      "14\n",
      "<type 'tuple'>\n",
      "2\n",
      "from average grads\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<type 'list'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "[-0.12390654, -0.10470416, 0.019343985, 0.00011018896, -0.00022458922, 0.00078803441, -0.0015130208, 8.7859109e-05, 2.7563281e-05, 0.00091913372, 0.003271075, 0.0047526076, 9.3132257e-10, -2.9802323e-09]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-56f5bf900070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         _, D_loss_curr = sess.run(\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mD_solver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_mb\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/annhe/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/annhe/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/annhe/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/annhe/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/local/0/annhe/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#100,000 is good\n",
    "#print every 1000\n",
    "g_loss_overall = []\n",
    "d_loss_overall = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for it in range(10000):\n",
    "        X_mb, y_mb = mnist.train.next_batch(mb_size)\n",
    "        X_mb = X_mb.reshape([mb_size, 28, 28, 1]) \n",
    "\n",
    "        _, D_loss_curr = sess.run(\n",
    "            [D_solver, D_loss], feed_dict={X: X_mb, y: y_mb}\n",
    "        )\n",
    "\n",
    "        _, G_loss_curr = sess.run(\n",
    "            [G_solver, G_loss], feed_dict={X: X_mb, y: y_mb}\n",
    "        )\n",
    "\n",
    "        if it % 100 == 0:\n",
    "            print('Iter: {}; D_loss: {:.4}; G_loss: {:.4}'\n",
    "              .format(it, D_loss_curr, G_loss_curr))\n",
    "        #D_grad = average_grads(D_grad_overall)\n",
    "        #D_grad_curr = sess.run(D_grad)\n",
    "            #D_grad_curr = average_grads(D_grad_overall, sess)\n",
    "            D_grad_cur_overall = sess.run(D_grad_overall, feed_dict={X: X_mb, y: y_mb})\n",
    "            D_grad_curr = average_grads(D_grad_cur_overall)\n",
    "            D_grad_eval = []\n",
    "            for grad in D_grad_curr:\n",
    "                D_grad_eval.append(grad.eval(session=sess))\n",
    "            print D_grad_eval\n",
    "            g_loss_overall.append(G_loss_curr)\n",
    "            d_loss_overall.append(D_loss_curr)\n",
    "        #z_mb = sample_z(16, z_dim)\n",
    "            samples = sess.run(G_sample)\n",
    "\n",
    "#         fig = plot(samples)\n",
    "#         plt.savefig(dir_name+'{}.png'\n",
    "#                     .format(str(i).zfill(3)), bbox_inches='tight')\n",
    "#         i += 1\n",
    "#         plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# #print g_loss_overall\n",
    "# #print d_loss_overall\n",
    "# g_loss_plot, = plt.plot(g_loss_overall, label='G Loss')\n",
    "# d_loss_plot, = plt.plot(d_loss_overall, label='D Loss')\n",
    "\n",
    "# plt.legend([g_loss_plot, d_loss_plot], ['G Loss', 'D Loss'])\n",
    "# plt.savefig(dir_name+'plot_for_catgan_.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
